{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/Users/apple/Documents/Train.csv\")\n",
    "train = train[['TweetText', 'Sentiment', 'Topic']]\n",
    "train = train[train.Sentiment != 'irrelevant']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train['TweetText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(\"/Users/apple/Documents/Test.csv\")\n",
    "test = test[['TweetText', 'Sentiment', 'Topic']]\n",
    "test = test[test.Sentiment != 'irrelevant']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test['TweetText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r= re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt=re.sub(i,'',input_txt)\n",
    "        \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tidy_tweet']=np.vectorize(remove_pattern)(train['TweetText'], \"@[\\w]*\")\n",
    "train['tidy_tweet']=train['tidy_tweet'].str.replace(\"[^a-z,A-z#]\",\" \")\n",
    "train['tidy_tweet']=train['tidy_tweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tidy_tweet']=np.vectorize(remove_pattern)(test['TweetText'], \"@[\\w]*\")\n",
    "test['tidy_tweet']=test['tidy_tweet'].str.replace(\"[^a-z,A-z#]\",\" \")\n",
    "test['tidy_tweet']=test['tidy_tweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = train['tidy_tweet'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = test['tidy_tweet'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer=PorterStemmer()\n",
    "tokenized_tweet=tokenized_tweet.apply(lambda x:[stemmer.stem(i) for i in x])\n",
    "tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud to explain train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words=' '.join([text for text in train['tidy_tweet']])\n",
    "from wordcloud import WordCloud\n",
    "wordcloud=WordCloud(width=1000, height=800, random_state=21, max_font_size=110).generate(train_words)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud to explain test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words=' '.join([text for text in test['tidy_tweet']])\n",
    "from wordcloud import WordCloud\n",
    "wordcloud=WordCloud(width=1000, height=800, random_state=21, max_font_size=110).generate(test_words)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the hashtag trends in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_extract(x):\n",
    "    hashtags=[]\n",
    "    for i in x:\n",
    "        ht=re.findall(r\"#(\\w+)\",i)\n",
    "        hashtags.append(ht)\n",
    "    return hashtags\n",
    "\n",
    "train_positive=hashtag_extract(train['tidy_tweet'][train['Sentiment']== 'positive'])\n",
    "train_negative=hashtag_extract(train['tidy_tweet'][train['Sentiment']=='negative'])\n",
    "train_neutral=hashtag_extract(train['tidy_tweet'][train['Sentiment']=='neutral'])\n",
    "\n",
    "train_positive_sum=sum(train_positive,[])\n",
    "train_negative_sum=sum(train_negative,[])\n",
    "train_neutral_sum=sum(train_neutral,[])\n",
    "\n",
    "a=nltk.FreqDist(train_positive_sum)\n",
    "d=pd.DataFrame({'Hashtag': list(a.keys()), 'Count':list(a.values())})\n",
    "d=d.nlargest(columns=\"Count\",n=10)\n",
    "plt.figure(figsize=(16,5))\n",
    "ax=sns.barplot(data=d, x= \"Hashtag\", y= \"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=nltk.FreqDist(train_negative_sum)\n",
    "e=pd.DataFrame({'Hashtag':list(b.keys()),'Count':list(b.values())})\n",
    "e=e.nlargest(columns=\"Count\",n=10)\n",
    "plt.figure(figsize=(16,5))\n",
    "ax=sns.barplot(data=e, x=\"Hashtag\", y=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=nltk.FreqDist(train_neutral_sum)\n",
    "h=pd.DataFrame({'Hashtag':list(g.keys()),'Count':list(g.values())})\n",
    "h=h.nlargest(columns=\"Count\",n=10)\n",
    "plt.figure(figsize=(16,5))\n",
    "ax=sns.barplot(data=h, x=\"Hashtag\", y=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(max_df=0.90, min_df=2, stop_words='english', max_features=1000)\n",
    "xtrain_vec=vectorizer.fit_transform(train['tidy_tweet'])\n",
    "xtest_vec=vectorizer.transform(test['tidy_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(train['tidy_tweet'])\n",
    "tfidf_test=tfidf_vectorizer.transform(test['tidy_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "ytrain = train['Sentiment']\n",
    "ytest = test['Sentiment']\n",
    "ztrain = train['Topic']\n",
    "ztest = test['Topic']\n",
    "#init logistic regression\n",
    "egg_sen=LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "egg_sen.fit(xtrain_vec, ytrain)\n",
    "egg_pred=egg_sen.predict(xtest_vec)\n",
    "print(accuracy_score(egg_pred,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(ytest, egg_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egg_top=LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "egg_top.fit(xtrain_vec, ztrain)\n",
    "egg_pred_1=egg_top.predict(xtest_vec)\n",
    "print(accuracy_score(egg_pred_1,ztest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "ham_sen=MultinomialNB()\n",
    "ham_sen.fit(xtrain_vec, ytrain)\n",
    "ham_pre=ham_sen.predict(xtest_vec)\n",
    "print(accuracy_score(ham_pre, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_top=MultinomialNB()\n",
    "ham_top.fit(xtrain_vec, ztrain)\n",
    "ham_pre_1=ham_top.predict(xtest_vec)\n",
    "print(accuracy_score(ham_pre_1, ztest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(egg_pred, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Topic':test['Topic'], 'NB_topic': ham_pre_1}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=input('File Link')\n",
    "new1=pd.read_csv(new)\n",
    "NS=new1['Sentiment']\n",
    "NTO=new1['Topic']\n",
    "\n",
    "new1['tidytweet'] = np.vectorize(remove_pattern)(new1['TweetText'], \"@[\\w]*\")\n",
    "new1['tidytweet'] = new1['tidytweet'].str.replace(\"[^a-z,A-z#]\",\" \")\n",
    "new1['tidytweet'] = new1['tidytweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))\n",
    "N_vec = vectorizer.transform(new1['tidytweet'])\n",
    "sen_new = egg_sen.predict(N_vec)\n",
    "top_new = egg_top.predict(N_vec)\n",
    "sen_new1 = ham_sen.predict(N_vec)\n",
    "top_new1 = ham_top.predict(N_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Accuracy of Sentiment Analysis by LogisticRegression',accuracy_score(sen_new, NS))\n",
    "#print('Accuracy of Topic Analysis by LogisticRegression', accuracy_score(top_new, NTO))\n",
    "#print('Accuracy of Sentiment Analysis by Naive Bayes',accuracy_score(sen_new1, NS))\n",
    "#print('Accuracy of Topic Analysis by Naive Bayes',accuracy_score(top_new1, NTO))\n",
    "\n",
    "accuracy_list={'Name':['Sentiment by LogisticRegression', 'Topic by LogisticRegression', 'Sentiment by Naive Bayes', 'Topic by Naive Bayes'],\n",
    "      'Accuracy':[accuracy_score(sen_new, NS), accuracy_score(top_new, NTO), accuracy_score(sen_new1, NS), accuracy_score(top_new1, NTO)]}\n",
    "df = pd.DataFrame(accuracy_list)\n",
    "\n",
    "ob=('senLR', 'topLR', 'senNB', 'topNB')\n",
    "y_pos = np.arange(len(ob))\n",
    "acc=(accuracy_score(sen_new, NS), accuracy_score(top_new, NTO), accuracy_score(sen_new1, NS), accuracy_score(top_new1, NTO))\n",
    "\n",
    "plt.bar(y_pos, acc, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, ob)\n",
    "plt.ylabel('score')\n",
    "plt.title('friendly lab1+2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n= pd.DataFrame({'TweetText': new1['TweetText'], 'Sentiment': new1['Sentiment'], 'Log_Sentiment': sen_new, 'NB_Sentiment': sen_new1, 'Topic': new1['Topic'], 'Log_Topic': top_new, 'NB_Topic': top_new1})\n",
    "n[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
